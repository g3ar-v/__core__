## core 

An AI-powered personal assistant equipped with an array of advanced components, including a robust wakeword system, an accurate speech recognizer, a cutting-edge speech synthesis module, and a sophisticated natural language generation powered by a state-of-the-art language model.
A middleware to integrate AI technology for automation, management, research and other purposes.
One of the remarkable features of this system lies in its versatility to seamlessly exchange specific components with alternative options. For instance, the text-to-speech functionality can be easily swapped from Mimic to ElevenLabs, demonstrating the system's adaptability and flexibility.


## Components

- Wakeword Listener (precise/porcupine)
- Automatic Speech Recognition/STT (Precise/Whisper)
- NLU/Intent parser (Adapt/Padatious)
- Skill (Main processing unit)
- TTS/Speech Synthesis (Mimic 3/ElevenLabs)

## Features
- Provide answers to user questions (online-dependent) 
- AI-powered personal assistant with a predisposed persona emulation
- partially precise speech recognizer (using offline whisper)
- icloud event reminder [demo](https://www.instagram.com/p/Cwa3Y0fMQh-/)

## RoadMap
- Fluid conversation
    - interruption remarks when user is speaking
- offline execution
- voice to IOS actions using osascript
- GUI's for elaboration of speech

## Aim
- Interact with the environment (realworld)
- Knowledge and deep analysis on user-provided data with environment
- Remember the interactions with user-provided data 
- modularity


## Links

- [OpenVoiceOS Documentation](https://openvoiceos.github.io/community-docs)
- [Mycroft Documentation](https://docs.mycroft.ai)
- [Mycroft API Docs](https://mycroft-core.readthedocs.io/en/master/)
- [Mycroft Forum](https://community.mycroft.ai)
- [Mycroft Blog](https://mycroft.ai/blog)
